{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ME 193, Spring 2021**\n",
    "## Final Project Notebook \n",
    "\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# install relavent modules and run once lines\n",
    "!pip install gensim\n",
    "!pip install boto3\n",
    "!pip install sagemaker\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.tree as tree\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.ensemble as ens\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor, NearestNeighbors\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# string workings\n",
    "import string\n",
    "from operator import itemgetter\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Amazon ML\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load kaggle database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150930\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "      <td>Heitz Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "      <td>Bodega Carmen Rodríguez Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "      <td>Macauley Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "      <td>Ponzi Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "      <td>Domaine de la Bégude Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery                                     name  \n",
       "0                    Heitz                 Heitz Cabernet Sauvignon  \n",
       "1  Bodega Carmen Rodríguez    Bodega Carmen Rodríguez Tinta de Toro  \n",
       "2                 Macauley                 Macauley Sauvignon Blanc  \n",
       "3                    Ponzi                         Ponzi Pinot Noir  \n",
       "4     Domaine de la Bégude  Domaine de la Bégude Provence red blend  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reds = pd.read_csv(os.path.join(\"Data\", \"winemag-data_first150k.csv\"))\n",
    "print(len(df_reds))\n",
    "df_reds.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "df_reds['name'] = df_reds['winery'] + ' ' + df_reds['variety']\n",
    "df_reds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample descrption\n",
    "df_reds.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "desc_train, desc_test, name_train, name_test = train_test_split(df_reds['description'],df_reds['name'], test_size=0.2, random_state=42)\n",
    "df_des_test = pd.DataFrame(list(zip(name_test, desc_test)),columns =['name', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bonterra Sauvignon Blanc</td>\n",
       "      <td>Nicely dry and crisp in clean acidity, this Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FiàNobile Nero d'Avola</td>\n",
       "      <td>This Nero d'Avola has aromas of earth, black c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sada Vermentino</td>\n",
       "      <td>This elegant Vermentino from Tuscany has a lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keenan Merlot</td>\n",
       "      <td>Not many Merlots deserve time in the cellar, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paumanok Cabernet Sauvignon</td>\n",
       "      <td>Crisp, elegant black-plum and cassis flavors a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "0     Bonterra Sauvignon Blanc   \n",
       "1       FiàNobile Nero d'Avola   \n",
       "2              Sada Vermentino   \n",
       "3                Keenan Merlot   \n",
       "4  Paumanok Cabernet Sauvignon   \n",
       "\n",
       "                                         description  \n",
       "0  Nicely dry and crisp in clean acidity, this Sa...  \n",
       "1  This Nero d'Avola has aromas of earth, black c...  \n",
       "2  This elegant Vermentino from Tuscany has a lov...  \n",
       "3  Not many Merlots deserve time in the cellar, b...  \n",
       "4  Crisp, elegant black-plum and cassis flavors a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_des = df_reds[['name','description']]\n",
    "df_des = pd.DataFrame(list(zip(name_train, desc_train)),columns =['name', 'description'])\n",
    "df_des.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = df_des[\"description\"].tolist()\n",
    "all_descriptions = [des for des in all_descriptions]\n",
    "#all_descriptions = [item for sublist in flavors_list for item in sublist]\n",
    "#print(all_descriptions[1])\n",
    "\n",
    "# Manipulate text\n",
    "full_corpus = ' '.join(all_descriptions)\n",
    "sentences_tokenized = sent_tokenize(full_corpus)\n",
    "stop_words = set(stopwords.words('english')) \n",
    "punctuation_table = str.maketrans({key: None for key in string.punctuation})\n",
    "sno = SnowballStemmer('english')\n",
    "\n",
    "def normalize_text(raw_text):\n",
    "    try:\n",
    "        word_list = word_tokenize(raw_text)\n",
    "        normalized_sentence = []\n",
    "        for w in word_list:\n",
    "            try:\n",
    "                w = str(w)\n",
    "                lower_case_word = str.lower(w)\n",
    "                stemmed_word = sno.stem(lower_case_word)\n",
    "                no_punctuation = stemmed_word.translate(punctuation_table)\n",
    "                if len(no_punctuation) > 1 and no_punctuation not in stop_words:\n",
    "                    normalized_sentence.append(no_punctuation)\n",
    "            except:\n",
    "                continue\n",
    "        return normalized_sentence\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nicely dry and crisp in clean acidity, this Sauvignon Blanc has flavors of limes, gooseberries, and vanilla.', \"But there's a lot of that notorious feline spray aroma and taste that detracts.\", \"This Nero d'Avola has aromas of earth, black currants, game and a note of grilled bell peppers.\", 'The palate offers fleeting black cherry and black berry, accented by black pepper and a green note of dried sage.', 'It finishes on a bitter note.', 'This elegant Vermentino from Tuscany has a lovely floral fragrance of white flowers and stone fruit accompanied by succulent peach and ripe pear flavors.', 'The fruit richness is balanced by crisp freshness.', 'Not many Merlots deserve time in the cellar, but this one does.', \"Such are its mountain tannins that it's in lockdown mode, with a tough, astringent finish.\", 'But just below the surface are voluptuously ripe flavors of blackberries, cherries and mulberries.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_tokenized[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cd9ea3e7672c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnormalized_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalized_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, common_terms)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36madd_vocab\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;31m# sufficient counts, before being pruned out by the (large) accumulated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# counts collected in previous learn_vocab runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         min_reduce, vocab, total_words = self.learn_vocab(\n\u001b[0m\u001b[1;32m    566\u001b[0m             sentences, self.max_vocab_size, self.delimiter, self.progress_per, self.common_terms)\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36mlearn_vocab\u001b[0;34m(sentences, max_vocab_size, delimiter, progress_per, common_terms)\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlast_uncommon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_uncommon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_between\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                         \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m                     \u001b[0mlast_uncommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0min_between\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "normalized_sentences = []\n",
    "for s in sentences_tokenized:\n",
    "    normalized_text = normalize_text(s)\n",
    "    normalized_sentences.append(normalized_text)\n",
    "\n",
    "phrases = Phrases(normalized_sentences)\n",
    "phrases = Phrases(phrases[normalized_sentences])\n",
    "\n",
    "ngrams = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da07c3457a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphrased_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormalized_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mphrased_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mphrased_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrased_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \"\"\"\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentence2token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m_sentence2token\u001b[0;34m(phrase_class, sentence)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0mnew_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36manalyze_sentence\u001b[0;34m(self, sentence, threshold, common_terms, scorer)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0;31m# release words individually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_uncommon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_between\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0min_between\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "phrased_sentences = []\n",
    "for sent in normalized_sentences:\n",
    "    phrased_sentence = ngrams[sent]\n",
    "    phrased_sentences.append(phrased_sentence)\n",
    "\n",
    "full_list_words = [item for sublist in phrased_sentences for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5af18caa3286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnormalized_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnormalized_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_mapped_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnormalized_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnormalized_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5af18caa3286>\u001b[0m in \u001b[0;36mreturn_mapped_descriptor\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreturn_mapped_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptor_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnormalized_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnormalized_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "descriptor_mapping = pd.read_csv(os.path.join(\"Data\", \"descriptor_mapping.csv\")).set_index('raw descriptor')\n",
    "\n",
    "def return_mapped_descriptor(word):\n",
    "    if word in list(descriptor_mapping.index):\n",
    "        normalized_word = descriptor_mapping['level_3'][word]\n",
    "        return normalized_word\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "normalized_sentences = []\n",
    "for sent in phrased_sentences:\n",
    "    normalized_sentence = []\n",
    "    for word in sent:\n",
    "        normalized_word = return_mapped_descriptor(word)\n",
    "        normalized_sentence.append(str(normalized_word))\n",
    "    normalized_sentence.append('.')\n",
    "    normalized_sentence_concat = ' '.join(normalized_sentence)\n",
    "    normalized_sentences.append(normalized_sentence_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store training data\n",
    "with open('wine_corpus.txt', 'w') as f:\n",
    "    for item in normalized_sentences:\n",
    "        f.write(\"{}\\n\".format(item))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploaded this data to AWS sagemaker blazingtext algo and trained the algorithim. Below we load in this training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x vectors.txt\n",
      "x eval.json\n",
      "x vectors.bin\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf dw_model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = len(open('vectors.txt','r').read().split('\\n'))\n",
    "\n",
    "first_line = True\n",
    "index_to_word = []\n",
    "with open(\"vectors.txt\",\"r\") as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if first_line:\n",
    "            dim = int(line.strip().split()[1])\n",
    "            word_vecs = np.zeros((num_points, dim), dtype=float)\n",
    "            first_line = False\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        word = line.split()[0]\n",
    "        vec = word_vecs[line_num-1]\n",
    "        for index, vec_val in enumerate(line.split()[1:]):\n",
    "            vec[index] = float(vec_val)\n",
    "        index_to_word.append(word)\n",
    "        if line_num >= num_points:\n",
    "            break\n",
    "word_vecs = normalize(word_vecs, copy=False, return_norm=False)\n",
    "\n",
    "names_vecs = list(zip(index_to_word, word_vecs))\n",
    "\n",
    "names_vecs_filtered = [n for n in names_vecs if n[0] in list(descriptor_mapping['level_3'])]\n",
    "\n",
    "names_vecs_df = pd.DataFrame(names_vecs_filtered, columns=['word', 'vector'])\n",
    "names_vecs_df.sort_values(by=['word'], inplace=True)\n",
    "names_vecs_df.to_csv('word_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names_vecs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fe7256f853a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdict_of_idf_weightings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'idf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mvectors_and_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames_vecs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_of_idf_weightings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mvectors_and_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_vec_idf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors_and_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvectors_and_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvectors_and_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors_and_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word_vec_idf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'names_vecs_df' is not defined"
     ]
    }
   ],
   "source": [
    "wine_reviews = list(df_des['description'])\n",
    "\n",
    "def return_descriptor_from_mapping(word):\n",
    "    if word in list(descriptor_mapping.index):\n",
    "        descriptor_to_return = descriptor_mapping['level_3'][word]\n",
    "        return descriptor_to_return\n",
    "\n",
    "descriptorized_reviews = []\n",
    "for review in wine_reviews:\n",
    "    normalized_review = normalize_text(review)\n",
    "    phrased_review = ngrams[normalized_review]\n",
    "    descriptors_only = [return_descriptor_from_mapping(word) for word in phrased_review]\n",
    "    no_nones = [str(d) for d in descriptors_only if d is not None]\n",
    "    descriptorized_review = ' '.join(no_nones)\n",
    "    descriptorized_reviews.append(descriptorized_review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wine_dataset_relevant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7a26b25520d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mwine_review_vectors_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_review_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'descriptors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_vector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'descriptor_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mfull_wine_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwine_dataset_relevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_review_vectors_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mfull_wine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mfull_wine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wine_dataset_relevant' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit(descriptorized_reviews)\n",
    "\n",
    "dict_of_idf_weightings = pd.DataFrame(zip(X.get_feature_names(), X.idf_), columns=['word', 'idf'])\n",
    "\n",
    "vectors_and_idf = pd.merge(left=names_vecs_df, right=dict_of_idf_weightings, left_on='word', right_on='word', how='inner')\n",
    "vectors_and_idf['word_vec_idf'] = vectors_and_idf['vector']*vectors_and_idf['idf']\n",
    "vectors_and_idf = vectors_and_idf[['word', 'word_vec_idf']]\n",
    "vectors_and_idf.set_index('word', inplace=True)\n",
    "vectors_and_idf.to_csv('word_vectors_idf.csv')\n",
    "\n",
    "wine_review_vectors = []\n",
    "for d in descriptorized_reviews:\n",
    "    descriptor_count = 0\n",
    "    weighted_review_terms = []\n",
    "    terms = d.split(' ')\n",
    "    \n",
    "    for term in terms:\n",
    "        if term in list(vectors_and_idf.index):\n",
    "            weighted_word_vector = vectors_and_idf.at[term, 'word_vec_idf']\n",
    "            weighted_review_terms.append(weighted_word_vector)\n",
    "            descriptor_count += 1\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        review_vector = sum(weighted_review_terms)/len(weighted_review_terms)\n",
    "    except:\n",
    "        review_vector = []\n",
    "    \n",
    "    vector_and_count = [terms, review_vector, descriptor_count]\n",
    "    wine_review_vectors.append(vector_and_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>descriptors</th>\n",
       "      <th>review_vector</th>\n",
       "      <th>descriptor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bonterra Sauvignon Blanc</td>\n",
       "      <td>Nicely dry and crisp in clean acidity, this Sa...</td>\n",
       "      <td>[dry, crisp, clean, lime, gooseberry, vanilla]</td>\n",
       "      <td>[0.35553248552071864, 0.12664773379889957, 0.1...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FiàNobile Nero d'Avola</td>\n",
       "      <td>This Nero d'Avola has aromas of earth, black c...</td>\n",
       "      <td>[earth, black_currant, game, bell_pepper, cher...</td>\n",
       "      <td>[0.08857546076556227, 0.2916090560683173, 0.36...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sada Vermentino</td>\n",
       "      <td>This elegant Vermentino from Tuscany has a lov...</td>\n",
       "      <td>[elegant, white_flower, stone, fruit, succulen...</td>\n",
       "      <td>[0.1750577682634161, 0.06123672302175332, 0.43...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keenan Merlot</td>\n",
       "      <td>Not many Merlots deserve time in the cellar, b...</td>\n",
       "      <td>[voluptuous, ripe, blackberry, cherry, mulberry]</td>\n",
       "      <td>[0.13224498524604655, 0.08915907766171047, 0.3...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paumanok Cabernet Sauvignon</td>\n",
       "      <td>Crisp, elegant black-plum and cassis flavors a...</td>\n",
       "      <td>[crisp, elegant, plum, cassis, fresh, herb, dr...</td>\n",
       "      <td>[0.31281359266367176, -0.12118656106173605, 0....</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "0     Bonterra Sauvignon Blanc   \n",
       "1       FiàNobile Nero d'Avola   \n",
       "2              Sada Vermentino   \n",
       "3                Keenan Merlot   \n",
       "4  Paumanok Cabernet Sauvignon   \n",
       "\n",
       "                                         description  \\\n",
       "0  Nicely dry and crisp in clean acidity, this Sa...   \n",
       "1  This Nero d'Avola has aromas of earth, black c...   \n",
       "2  This elegant Vermentino from Tuscany has a lov...   \n",
       "3  Not many Merlots deserve time in the cellar, b...   \n",
       "4  Crisp, elegant black-plum and cassis flavors a...   \n",
       "\n",
       "                                         descriptors  \\\n",
       "0     [dry, crisp, clean, lime, gooseberry, vanilla]   \n",
       "1  [earth, black_currant, game, bell_pepper, cher...   \n",
       "2  [elegant, white_flower, stone, fruit, succulen...   \n",
       "3   [voluptuous, ripe, blackberry, cherry, mulberry]   \n",
       "4  [crisp, elegant, plum, cassis, fresh, herb, dr...   \n",
       "\n",
       "                                       review_vector  descriptor_count  \n",
       "0  [0.35553248552071864, 0.12664773379889957, 0.1...                 6  \n",
       "1  [0.08857546076556227, 0.2916090560683173, 0.36...                11  \n",
       "2  [0.1750577682634161, 0.06123672302175332, 0.43...                12  \n",
       "3  [0.13224498524604655, 0.08915907766171047, 0.3...                 5  \n",
       "4  [0.31281359266367176, -0.12118656106173605, 0....                13  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_review_vectors_df = pd.DataFrame(wine_review_vectors, columns=['descriptors', 'review_vector', 'descriptor_count'])\n",
    "full_wine_df = pd.concat([df_des, wine_review_vectors_df], axis=1)\n",
    "full_wine_df.dropna(how='any', inplace=True)\n",
    "full_wine_df.to_csv('wine_review_vectors.csv')\n",
    "full_wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = pd.DataFrame(full_wine_df['review_vector'].values.tolist())\n",
    "X_in.dropna(inplace=True)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=10, algorithm= 'brute', metric='cosine')\n",
    "model_knn = knn.fit(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_wine_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f21beffc717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"FiàNobile Nero d'Avola\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwine_test_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_wine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfull_wine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_test_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdistance_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_wine_df' is not defined"
     ]
    }
   ],
   "source": [
    "name_test = \"Ponzi Pinot Noir\"\n",
    "\n",
    "wine_test_vector = full_wine_df.loc[full_wine_df['name'] == name_test]['review_vector'].values.tolist()\n",
    "distance, indice = model_knn.kneighbors(wine_test_vector, n_neighbors=9)\n",
    "distance_list = distance[0].tolist()[1:]\n",
    "indice_list = indice[0].tolist()[1:]\n",
    "\n",
    "main_wine = full_wine_df.loc[full_wine_df['name'] == name_test]\n",
    "\n",
    "print('Similar to:', name_test)\n",
    "print('The input wine is:', list(main_wine['descriptors'])[0])\n",
    "print('_________')\n",
    "\n",
    "n = 1\n",
    "for d, i in zip(distance_list, indice_list):\n",
    "    wine_name = full_wine_df['name'][i]\n",
    "    wine_descriptors = full_wine_df['description'][i]\n",
    "    print('Suggestion', str(n), ':', wine_name, 'distance of', \"{:.3f}\".format(d))\n",
    "    print('and descriptors:', wine_descriptors)\n",
    "    print('')\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35553249,  0.12664773,  0.10936317, -0.1851383 , -0.08707049,\n",
       "       -0.12340965, -0.42339151,  0.14701959, -0.04237249, -0.17965019,\n",
       "       -0.16699341,  0.38249065, -0.09582436, -0.0750661 , -0.2373822 ,\n",
       "        0.01867774,  0.17329456, -0.10708956, -0.51685525,  0.05198096,\n",
       "        0.28612537,  0.1801171 , -0.21623886,  0.16318324, -0.33091892,\n",
       "       -0.6527566 ,  0.15825395,  0.08690007, -0.36082418,  0.4051321 ,\n",
       "        0.37151455,  0.33333824, -0.15032933, -0.2182742 , -0.56823643,\n",
       "        0.08133293,  0.42180671, -0.49673054, -0.25735572,  0.10638138,\n",
       "        0.31177079,  0.51083162, -0.16639676,  0.10728115,  0.16802243,\n",
       "       -0.36764116,  0.39267951,  0.09907775,  0.07439442, -0.05432674,\n",
       "       -0.47212013, -0.06742511, -0.07993969,  0.14794919, -0.15414799,\n",
       "       -0.06095944, -0.06507937,  0.44334476,  0.3237873 ,  0.15351034,\n",
       "       -0.00682876, -0.27190679,  0.53236101,  0.09943219,  0.16252907,\n",
       "       -0.02505279, -0.25117823, -0.06461226, -0.10616461, -0.37247474,\n",
       "       -0.35618969,  0.18241851,  0.56859201,  0.19560004, -0.30965396,\n",
       "        0.14817211,  0.77511968,  0.24666605, -0.07473845, -0.14127699,\n",
       "        0.56010605,  0.01764237, -0.29185536,  0.00809491,  0.20586914,\n",
       "        0.31104836,  0.23102888,  0.33855137, -0.00098596,  0.48077008,\n",
       "       -0.04944306, -0.1176071 ,  0.68807477, -0.41154331,  0.18810802,\n",
       "       -0.30255297, -0.5489832 ,  0.07453523, -0.20996817,  0.04787264])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
